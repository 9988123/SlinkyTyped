package typingsSlinky.tensorflowTfjsLayers.activationConfigMod

import org.scalablytyped.runtime.TopLevel
import typingsSlinky.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.elu_
import typingsSlinky.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.hard_sigmoid
import typingsSlinky.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.linear
import typingsSlinky.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.relu6
import typingsSlinky.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.relu_
import typingsSlinky.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.selu
import typingsSlinky.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.sigmoid
import typingsSlinky.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.softmax_
import typingsSlinky.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.softplus
import typingsSlinky.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.softsign
import typingsSlinky.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.tanh
import scala.scalajs.js
import scala.scalajs.js.`|`
import scala.scalajs.js.annotation._

@JSImport("@tensorflow/tfjs-layers/dist/keras_format/activation_config", "activationOptions")
@js.native
object activationOptions
  extends TopLevel[
      js.Array[
        elu_ | hard_sigmoid | linear | relu_ | relu6 | selu | sigmoid | softmax_ | softplus | softsign | tanh
      ]
    ]

